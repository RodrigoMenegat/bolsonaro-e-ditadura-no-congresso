{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formata-texto\n",
    "Esse script recebe arquivos .txt extraídos do site da Câmara dos Deputados e executa operações de limpeza e formatação usando regex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importação de pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VARIÁVEL GLOBAL PARA TESTAR VÁRIOS ENCODINGS\n",
    "encoding = 'UTF-8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ler arquivos externos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_fpaths(dir_path, pattern):\n",
    "    '''\n",
    "    >> DESCRIÇÃO\n",
    "    \n",
    "    Usa o módulo glob para buscar todos os arquivos\n",
    "    que correspondam ao padrão passado na variável \n",
    "    pattern'. Retorna uma lista de paths no formato \n",
    "    string. \n",
    "    \n",
    "    >> PARÂMETROS\n",
    "    \n",
    "    dir_path -> uma string com o caminho para o\n",
    "    diretório onde a busca pelos arquivos será\n",
    "    realizada.\n",
    "    \n",
    "    pattern -> uma string com o padrão de texto\n",
    "    que deve ser procurado no diretório.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    full_pattern = dir_path + pattern\n",
    "    files = glob.glob(full_pattern)\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_df_plen(file_list):\n",
    "    '''\n",
    "    >> DESCRIÇÃO\n",
    "    \n",
    "    Lê a lista de arquivos e configura o conteúdo\n",
    "    em um dataframe com os seguintes campos:\n",
    "    PRESIDENTE | CONTEUDO | ARQUIVO | ANO\n",
    "    Funciona para os discursos em plenário\n",
    "    \n",
    "    >> PARÂMETROS\n",
    "    \n",
    "    file_list -> uma lista de filepaths em formato\n",
    "    string. Ela é gerada anteriormente, na função\n",
    "    find_fpaths.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Lê o conteúdo dos arquivos de texto na lista\n",
    "    content = [ open(file, encoding = encoding).read() for file in file_list ]\n",
    "    file_list = [ unidecode(file) for file in file_list ]\n",
    "    \n",
    "    # Transforma eum dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'FILE'             : [ file for file in file_list ],\n",
    "        'ORIGINAL_CONTENT' : [ item for item in content ],\n",
    "        'CLEAN_CONTENT'    : [ unidecode(item) for item in content ],\n",
    "        'SESSION_TYPE'     : [ re.search(\"\\-([A-Z\\s]+)\\-\", file).group(1) for file in file_list ],\n",
    "        'SESSION_DATE'     : [ re.search(\"\\d{8}\", file).group(0) for file in file_list ]\n",
    "    })\n",
    "    \n",
    "    df[\"SESSION_DATE\"] = pd.to_datetime(df.SESSION_DATE, format = \"%d%m%Y\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_df_com(file_list):\n",
    "    '''\n",
    "    >> DESCRIÇÃO\n",
    "    \n",
    "    Lê a lista de arquivos e configura o conteúdo\n",
    "    em um dataframe com os seguintes campos:\n",
    "    PRESIDENTE | CONTEUDO | ARQUIVO | ANO\n",
    "    Funciona para os discursos em comissão\n",
    "    \n",
    "    >> PARÂMETROS\n",
    "    \n",
    "    file_list -> uma lista de filepaths em formato\n",
    "    string. Ela é gerada anteriormente, na função\n",
    "    find_fpaths.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Lê o conteúdo dos arquivos de texto na lista\n",
    "    content = [ open(file, encoding = encoding).read() for file in file_list ]\n",
    "    file_list = [ unidecode(file) for file in file_list ]\n",
    "    \n",
    "    # Transforma eum dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'FILE'             : [ file for file in file_list ],\n",
    "        'ORIGINAL_CONTENT' : [ item for item in content ],\n",
    "        'CLEAN_CONTENT'    : [ unidecode(item) for item in content ],\n",
    "        'SESSION_TYPE'     : [ 'COMISSÃO ESPECIAL (FORA DO PLENÁRIO)' for file in file_list ],\n",
    "        'SESSION_DATE'     : [ re.search(\"\\d{8}\", file).group(0) for file in file_list ]\n",
    "    })\n",
    "    \n",
    "    df[\"SESSION_DATE\"] = pd.to_datetime(df.SESSION_DATE, format = \"%d%m%Y\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções de formatação e busca usando regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_speakers(string):\n",
    "    \n",
    "    '''\n",
    "    Essa função detecta o padrão de texto\n",
    "    que antecede a fala de um deputado e\n",
    "    retorna um objeto match (via re.find_all).\n",
    "    Ele é útil para detectar QUANTOS deputados\n",
    "    falaram em determinada string textual.\n",
    "    '''\n",
    "    \n",
    "    pattern = \"((O?\\s?SR\\.?\\s+?)|(A?\\s?SRA\\.?\\s+?))(\\s+DEPUTADO|\\s+DEPUTADA|\\s+PRESIDENTE|\\s+PRESIDENTA)?\"\n",
    "    regexp = re.compile(pattern)\n",
    "    matches = re.findall(regexp, string)\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_full_quote(clean_string, original_string):\n",
    "    \n",
    "    '''\n",
    "    Essa função extrai todas as falas de Jair Bolsonaro\n",
    "    em uma determinada string. O pattern de regex encontra,\n",
    "    primeiro, uma fala qualquer do Presidente. Então, pega\n",
    "    tudo que está entre essa fala e a fala de outro parlamentar \n",
    "    ou o fim do arquivo. Isso é necessário porque há arquivos\n",
    "    que misturam a fala de vários parlamentares, geralmente\n",
    "    quando estão envolvidos em uma discussão.\n",
    "    \n",
    "    Para fazer essa operação, são passados textos sem caracteres\n",
    "    especiais unicode. Depois de feita a captura, usamos os índices\n",
    "    das matches no regex para extrair o mesmo pedaço de texto\n",
    "    na string original.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    if \"O SR. PRESIDENTE (Jair Bolsonaro)\" in clean_string:\n",
    "        pattern = \"O SR\\. PRESIDENTE (\\(Jair Bolsonaro\\))?(.*?)((O?\\s?SR\\.?\\s+?)|(A?\\s?SRA\\.?\\s+?)|$)\"\n",
    "        group_no = 2\n",
    "\n",
    "    else:\n",
    "        pattern  = \"O?\\s?SR\\.?\\s?(DEPUTADO)?\\s+JAIR\\s+BOLSONARO\\s?(\\((Bloco\\/)?\\w{2,}\\s?\\-\\s?\\w{2}[^)]+\\))?(.*?)((O?\\s?SR\\.?\\s+?)|(A?\\s?SRA\\.?\\s+?)|$)\"\n",
    "        group_no = 4\n",
    "        \n",
    "    regexp   = re.compile(pattern, re.MULTILINE)\n",
    "    matches  = re.finditer(regexp, clean_string)\n",
    "    \n",
    "    full_clean_quote    = [ ]\n",
    "    full_original_quote = [ ]\n",
    "    \n",
    "    for match in matches:\n",
    "                        \n",
    "        match_start = match.start(group_no)\n",
    "        match_end   = match.end(group_no)\n",
    "            \n",
    "        clean_quote = match[group_no]\n",
    "        clean_quote = clean_quote.replace(\"- \", \"\")\n",
    "        \n",
    "        original_quote = original_string[match_start:match_end]\n",
    "        original_quote = original_quote.replace(\"- \", \"\")\n",
    "        \n",
    "        full_clean_quote.append(clean_quote)\n",
    "        full_original_quote.append(original_quote)\n",
    "        \n",
    "    full_clean_quote    = ' [ INTERRUPÇÃO ] '.join(full_clean_quote)\n",
    "    full_original_quote = ' [ INTERRUPÇÃO ] '.join(full_original_quote)\n",
    "    \n",
    "#     # Limpa caractere maluco que aparece no começo de alguns textos\n",
    "#     if full_original_quote.startswith('â'):\n",
    "#         full_original_quote = full_original_quote[3:] # Esse caractere é sempre seguido de um mais dois lixinhos\n",
    "    \n",
    "#     if full_clean_quote.startswith('a'):\n",
    "#         full_clean_quote = full_clean_quote[1:] # Os caracteres posteriores já foram obliterados pelo unidecode\n",
    "        \n",
    "    # Remove espaços múltiplos internos usando a operação join de lista\n",
    "    full_clean_quote    = ' '.join(full_clean_quote.split()) \n",
    "    full_original_quote = ' '.join(full_original_quote.split()) \n",
    "    \n",
    "#     print(f\"FULL_CLEAN_QUOTE:\\n{full_clean_quote}\\n\")\n",
    "#     print(f\"FULL_ORIGINAL_QUOTE:\\n{full_original_quote}\\n\")\n",
    "    \n",
    "    return full_clean_quote, full_original_quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções para aplicar operações de regex no dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_count_speakers(row):\n",
    "    \n",
    "    '''\n",
    "    Aplica, linha a linha, a função\n",
    "    find_speakers(string)\n",
    "    '''\n",
    "    \n",
    "    matches = find_speakers(row.CLEAN_CONTENT)\n",
    "    speaker_count = len(matches)\n",
    "    \n",
    "    return pd.Series({ \"SPEAKER_COUNT\":speaker_count \n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_extract_full_quote(row):\n",
    "    \n",
    "    '''\n",
    "    Aplica, linha a linha, a função\n",
    "    extract_full_quote(string)\n",
    "    '''\n",
    "    \n",
    "    full_clean_quote, full_original_quote = extract_full_quote(row.CLEAN_CONTENT, row.ORIGINAL_CONTENT)\n",
    "    return pd.Series({\n",
    "        \"FULL_CLEAN_QUOTE\"    : full_clean_quote,\n",
    "        \"FULL_ORIGINAL_QUOTE\" : full_original_quote\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função que encapsula anteriores e roda a operação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_script():\n",
    "    \n",
    "    '''\n",
    "    Executa as operações anteriores em ambos os bancos de dados\n",
    "    (plenário e comissões), filtra entradas sem match, concatena\n",
    "    ambos os dataframes e salva para arquivo csv.\n",
    "    '''\n",
    "    \n",
    "    # Monta dataframes\n",
    "    jb_plen = make_df_plen( find_fpaths(\"../data/txts/plenario/\", \"*.txt\") )\n",
    "    jb_com  = make_df_com( find_fpaths(\"../data/txts/comissao/\", \"*.txt\") )\n",
    "    \n",
    "    # As sessões do tipo HOMENAGEM são apenas registro de protocolo. \n",
    "    # Não contém transcrição de discursos.\n",
    "    jb_plen = jb_plen[ jb_plen.SESSION_TYPE != \"HOMENAGEM\" ]\n",
    "    \n",
    "    # Aplica funções para extrair discursos\n",
    "    jb_plen[\"SPEAKER_COUNT\"] = jb_plen.apply(apply_count_speakers, axis=1)\n",
    "    jb_plen = jb_plen.join(jb_plen.apply(apply_extract_full_quote, axis=1))\n",
    "    \n",
    "#     jb_com[\"SPEAKER_COUNT\"]  = jb_com.apply(apply_count_speakers, axis=1)\n",
    "#     jb_com = jb_com.join(jb_com.apply(apply_extract_full_quote, axis=1))\n",
    "    \n",
    "    # Há sim entradas que não tiveram match algum\n",
    "    # Verifiquei manualmente e elas são de discursos\n",
    "    # que o site da Câmara retornou erroneamente.\n",
    "    # De fato não contém falas de Bolsonaro.\n",
    "    \n",
    "    jb_plen = jb_plen[ jb_plen.FULL_CLEAN_QUOTE != \"\" ]\n",
    "#     jb_com  = jb_com[ jb_com.FULL_CLEAN_QUOTE != \"\" ]\n",
    "    \n",
    "#     jb = pd.concat( [ jb_plen, jb_com ] )\n",
    "    \n",
    "    # Salva\n",
    "    directory = \"../data/csvs/\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    fname = directory + \"discursos_jair_bolsonaro.csv\" \n",
    "    jb_plen.to_csv(fname, index = False)\n",
    "#    jb.to_csv(fname, index = False)\n",
    "    \n",
    "    return jb_plen\n",
    "#    return jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = run_script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
