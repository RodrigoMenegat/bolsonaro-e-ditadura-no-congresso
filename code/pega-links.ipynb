{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pega-links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse script coleta os links para os pronunciamentos de um determinado parlamentar que estão registrados no [banco de dados de discursos e notas taquigráficas](https://www2.camara.leg.br/atividade-legislativa/discursos-e-notas-taquigraficas) da Câmara dos Deputados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importação de pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções para executar a busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_url(txOrador = '', \n",
    "             txPartido = '', \n",
    "             txUf = '', \n",
    "             dtInicio = '', \n",
    "             dtFim = '',\n",
    "             txTexto = '',\n",
    "             txSumario = '',\n",
    "             basePesq  = 'plenario',\n",
    "             CampoOrdenacao = 'dtSessao',\n",
    "             PageSize = '50',\n",
    "             TipoOrdenacao = 'DESC'):\n",
    "    \n",
    "    '''\n",
    "    Essa função cria a url de busca no sistema de arquivo da Câmara.\n",
    "    Ao menos um dos campos cujo valor default é '' precisa ser preenchido.\n",
    "    '''\n",
    "    \n",
    "    search_values = [ True for item in [txOrador, txPartido, txUf, dtInicio, dtFim, txTexto, txSumario] if item != '' ]\n",
    "    \n",
    "    if not any(search_values):\n",
    "        raise Exception(\"Para a URL retornar uma requisição válida, é necessário passar ao menos um parâmetro de busca.\")\n",
    "    \n",
    "    # url de busca\n",
    "    base_url = \"https://www.camara.leg.br/internet/sitaqweb/resultadoPesquisaDiscursos.asp?\"\n",
    "    \n",
    "    # Essa síntaxe define uma string longa sem quebras de linhas ou espaços\n",
    "    params = (\n",
    "    \"txOrador={txOrador}\"\n",
    "    \"&txPartido={txPartido}\"\n",
    "    \"&txUF={txUF}\"\n",
    "    \"&dtInicio={dtInicio}\"\n",
    "    \"&dtFim={dtFim}\"\n",
    "    \"&txTexto={txTexto}\"\n",
    "    \"&txSumario={txSumario}\"\n",
    "    \"&basePesq={basePesq}\"\n",
    "    \"&CampoOrdenacao={CampoOrdenacao}\"\n",
    "    \"&PageSize={PageSize}\")\n",
    "    \n",
    "    # Substitui os valores na string param\n",
    "    params = params.format(\n",
    "        txOrador = txOrador, \n",
    "        txPartido = txPartido, \n",
    "        txUF = txUf, \n",
    "        dtInicio = dtInicio, \n",
    "        dtFim = dtFim, \n",
    "        txTexto = txTexto,\n",
    "        txSumario = txSumario, \n",
    "        basePesq = basePesq, \n",
    "        CampoOrdenacao = CampoOrdenacao, \n",
    "        PageSize = PageSize, \n",
    "        TipoOrdenacao = TipoOrdenacao\n",
    "    )\n",
    "    \n",
    "    # Compõe url final\n",
    "    url = base_url + params\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_request(url):\n",
    "    \n",
    "    '''\n",
    "    Faz uma requisição para a url desejada\n",
    "    e retorna um valor textual\n",
    "    '''\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    r.encoding = 'UTF-8' # Muda encoding para evitar erros de caractere\n",
    "    \n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raspagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_soup(data):\n",
    "    '''\n",
    "    Recebe uma string de texto e retorna um objeto do BeautifulSoup.\n",
    "    '''\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_table(soup, basePesq):\n",
    "    \n",
    "    '''\n",
    "    Pega os dados da tabela na paginação atual\n",
    "    e salva para uma lista passado como parâmetro.\n",
    "    \n",
    "    Parâmetros:\n",
    "    \n",
    "    soup -> Documento parseado pelo BeautifulSoup\n",
    "    database -> String que determina em que base\n",
    "    de dados a busca deve ser executada: 'plenario'\n",
    "    ou 'comissao'.\n",
    "    '''\n",
    "    \n",
    "    if basePesq == 'plenario':\n",
    "        data = scrape_plen(soup)\n",
    "        \n",
    "    elif basePesq == 'comissao':\n",
    "        data = scrape_com(soup)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_plen(soup):\n",
    "    \n",
    "    '''\n",
    "    Função que raspa dados das manifestações\n",
    "    do parlamentar em plenário.\n",
    "    \n",
    "    Parâmetros:\n",
    "    \n",
    "    soup -> Documento parseado pelo BeautifulSoup\n",
    "    '''\n",
    "    \n",
    "    # Encontra a tabela\n",
    "    table = soup.find('table')\n",
    "\n",
    "    # Encontra os cabeçalhos\n",
    "    headers = table.find_all('th')\n",
    "\n",
    "    # Cria uma lista para cada cabeçalho em um dicionário\n",
    "    data = { header.text : [] for header in headers }\n",
    "\n",
    "    # Acessa apenas o corpo da tabela\n",
    "    table_body = table.find('tbody')\n",
    "\n",
    "    # Acessa cada linha do corpo da tabela\n",
    "    rows = table_body.find_all('tr')\n",
    "        \n",
    "    # Filtra linhas estranhas que não carregam dados\n",
    "    rows = [ row for row in rows if not row.has_attr(\"name\") ]\n",
    "\n",
    "    for row in rows:         \n",
    "\n",
    "        # Encontra todas as células da tabela\n",
    "        cells = row.find_all('td')\n",
    "\n",
    "        # Sempre teremos oito células.\n",
    "        # Podemos salvá-las na ordem da lista em seus respectivos campos.\n",
    "        data[\"Data\"].append(cells[0].text)\n",
    "        data[\"Sessão\"].append(cells[1].text)\n",
    "        data[\"Fase\"].append(cells[2].text)\n",
    "\n",
    "        # Não há links para uma transcrição em html para dados mais antigos.\n",
    "        # Assim, aso o script encontre um TypeError (por tentar acessar o atributo \n",
    "        # 'href de um elemento None-type), a saída é preencher com o texto.\n",
    "        try:\n",
    "            data[\"Discurso\"].append(cells[3].find('a')['href'])\n",
    "        except TypeError:\n",
    "            data[\"Discurso\"].append(cells[3].text)\n",
    "\n",
    "        data[\"Sumário\"].append(cells[4].find('a')['title'])\n",
    "        data[\"Orador\"].append(cells[5].text)\n",
    "        data[\"Hora\"].append(cells[6].text)\n",
    "\n",
    "        # Mesmo problema do campo 'Discurso', com a mesma solução\n",
    "        try:\n",
    "            # Aqui, estamos acessando um atributo que tem os parâmetros\n",
    "            # para uma função JavaScript que monta a URL onde podemos acessar o PDF\n",
    "            data[\"Publicação\"].append(cells[7].find('a')['onclick'])\n",
    "        except (TypeError, KeyError): \n",
    "            data[\"Publicação\"].append(cells[7].text)\n",
    "\n",
    "    # Tira os brancos desnecessários de todas as listas\n",
    "    # e faz alterações em sessões particulares\n",
    "    for key, value in data.items():\n",
    "        data[key] = [ item.strip() for item in value ]\n",
    "\n",
    "        if key == 'Discurso':\n",
    "            new_data = [ item.replace(\"\\r\\n\\t\\t\\t\\t\\t\\t\\t\", \"\") for item in value ]\n",
    "            new_data = [ \"https://www.camara.leg.br/internet/sitaqweb/\" + item if item != '\\xa0' else '-' for item in new_data ]\n",
    "            data[key] = new_data\n",
    "\n",
    "        if key == 'Sumário':\n",
    "            new_data = [ item.replace(\"Sumário:\\xa0\", \"\") for item in value ]\n",
    "            data[key] = new_data\n",
    "            \n",
    "        if key == 'Publicação':\n",
    "            new_data = [ item.replace('MostraImagem','') if 'MostraImagem' in item else '' for item in value ]\n",
    "            new_data = [ item.replace('(', '').replace(')', '') for item in new_data ]\n",
    "            new_data = [ item.replace(\"'\", \"\") for item in new_data]\n",
    "            new_data = [ item.split(',') for item in new_data ] # Se não há o que splitar, retorna uma lista vazia\n",
    "            new_data = [ build_pdf_link(item) for item in new_data]\n",
    "            data[key] = new_data\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_com(soup):\n",
    "\n",
    "    '''\n",
    "    Função que raspa dados das manifestações\n",
    "    do parlamentar nas comissões.\n",
    "    '''\n",
    "    \n",
    "    # Encontra a tabela\n",
    "    table = soup.find('table')\n",
    "\n",
    "    # Encontra os cabeçalhos\n",
    "    headers = table.find_all('th')\n",
    "\n",
    "    # Cria uma lista para cada cabeçalho em um dicionário\n",
    "    data = { header.text : [] for header in headers }\n",
    "\n",
    "    # Acessa apenas o corpo da tabela\n",
    "    table_body = table.find('tbody')\n",
    "\n",
    "    # Acessa cada linha do corpo da tabela\n",
    "    rows = table_body.find_all('tr')\n",
    "        \n",
    "    # Filtra linhas estranhas que não carregam dados\n",
    "    rows = [ row for row in rows if not row.has_attr(\"name\") ]\n",
    "\n",
    "    for row in rows:         \n",
    "\n",
    "        # Encontra todas as células da tabela\n",
    "        cells = row.find_all('td')\n",
    "\n",
    "        # Sempre teremos oito células.\n",
    "        # Podemos salvá-las na ordem da lista em seus respectivos campos.\n",
    "        data[\"Data\"].append(cells[0].text)\n",
    "        data[\"Reunião\"].append(cells[1].text)\n",
    "        data[\"Tipo\"].append(cells[2].text)\n",
    "        data[\"Texto\"].append(cells[3].find('a')['href'])\n",
    "        data[\"Comissão\"].append(cells[4].text)\n",
    "        data[\"Hora\"].append(cells[5].text)\n",
    "\n",
    "    # Tira os brancos desnecessários de todas as listas\n",
    "    # e faz alterações em sessões particulares\n",
    "    for key, value in data.items():\n",
    "        data[key] = [ item.strip() for item in value ]\n",
    "        \n",
    "        if key == 'Texto':\n",
    "            new_data = [ item.replace(\"\\r\\n\\t\\t\\t\\t\\t\", \"\") for item in value ]\n",
    "            new_data = [ \"https://www.camara.leg.br/internet/sitaqweb/\" + item if item != '\\xa0' else '-' for item in new_data ]\n",
    "            data[key] = new_data\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_pdf_link(array):\n",
    "    \n",
    "    '''\n",
    "    Com base no array de argumentos que retiramos de um parâmetro\n",
    "    do campo 'Publicação' da tabela, podemos chamar uma função\n",
    "    que reconstrói o link para acessar o PDF do discurso.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if len(array) != 4:\n",
    "        return 'no_link'\n",
    "    \n",
    "    # Precismamos transformar o primeiro elemento no\n",
    "    # valor correto para gerar a url do PDF.\n",
    "    if \"DCD\" in array[0]:\n",
    "        array[0] = \"D\"\n",
    "    elif \"DCNR\" in array[0]:\n",
    "        array[0] = \"R\"\n",
    "    elif \"DCN\" in array[0]:\n",
    "        array[0] = \"J\"\n",
    "    elif \"DANC\" in array[0]:\n",
    "        array[0] = \"R\"\n",
    "    elif \"ANA\" in array[0]:\n",
    "        array[0] = \"A\"\n",
    "        \n",
    "    # Uma vez alterado o primeiro elemento, basta formatar\n",
    "    # a seguinte url com base no array do parâmetros\n",
    "    url = (\"http://imagem.camara.gov.br/dc_20.asp\"\n",
    "           \"?selCodColecaoCsv={}\"\n",
    "           \"&txPagina={}\"\n",
    "           \"&Datain={}\"\n",
    "           \"&txSuplemento={}\")\n",
    "    \n",
    "    # O asterisco permite passar uma lista de argumentos \n",
    "    # de tamanho desconhecido para o método .format (*args)\n",
    "    url = url.format(*array)\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rodar raspador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_scraper(**kwargs):\n",
    "    \n",
    "    '''\n",
    "    Função que encapsula as definidas anteriormente,\n",
    "    converte o output para dataframe e salva como csv.\n",
    "    '''\n",
    "    \n",
    "    url = build_url(txOrador = kwargs[\"txOrador\"], \n",
    "                    PageSize = kwargs[\"PageSize\"], \n",
    "                    basePesq = kwargs[\"basePesq\"])\n",
    "    \n",
    "    doc = make_request(url)\n",
    "    soup = make_soup(doc)\n",
    "    data = scrape_table(soup = soup, basePesq = kwargs[\"basePesq\"])\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    \n",
    "    fpath = \"../data/tables/{txOrador}-{basePesq}-metadata.csv\"\n",
    "    fpath = fpath.format(\n",
    "        txOrador = kwargs[\"txOrador\"].replace(\"+\",\"-\"),\n",
    "        basePesq = kwargs[\"basePesq\"],\n",
    "    )\n",
    "    df.to_csv(fpath, index = False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A célula abaixo executa o código e salva outputs no formato csv\n",
    "kwargs = {\n",
    "    \"txOrador\":\"jair+bolsonaro\",\n",
    "    \"PageSize\":\"2000\",\n",
    "    \"basePesq\":\"plenario\",\n",
    "}\n",
    "\n",
    "run_scraper(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Altera a base de pesquisa e roda novamente\n",
    "kwargs[\"basePesq\"] = \"comissao\"\n",
    "run_scraper(**kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
